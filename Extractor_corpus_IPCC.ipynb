{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ff87966c4314b7c8806cbf1acfe3903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_605bb1868b7e49c5bd111ecffa6d2f10",
              "IPY_MODEL_758d2193fafc4c239e9d629447744b0e",
              "IPY_MODEL_98fe04f35e6c4776a8dca2103f0d004a"
            ],
            "layout": "IPY_MODEL_cb71e9946c304f78b96621860adb1d65"
          }
        },
        "605bb1868b7e49c5bd111ecffa6d2f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f5aa13ad51a44ba8cfda740d731caf1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e2c67d678fe844c6a9e32eb1f856b95f",
            "value": "Cargando‚Äáscores:‚Äá"
          }
        },
        "758d2193fafc4c239e9d629447744b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d9215993be4bbc871e00bd5a749cc1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a82a932f80747cbb968acfe4c72709c",
            "value": 0
          }
        },
        "98fe04f35e6c4776a8dca2103f0d004a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f540b7c8c7bb436e8d319887c81bb305",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba2831acdad744cea56586bd8830d21e",
            "value": "‚Äá0/0‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "cb71e9946c304f78b96621860adb1d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5aa13ad51a44ba8cfda740d731caf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c67d678fe844c6a9e32eb1f856b95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29d9215993be4bbc871e00bd5a749cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7a82a932f80747cbb968acfe4c72709c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f540b7c8c7bb436e8d319887c81bb305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2831acdad744cea56586bd8830d21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## EXTRACCI√ìN CORPUS IPCC: 400 DOCUMENTOS NECESARIOS PARA CORPUS"
      ],
      "metadata": {
        "id": "MdNOH1puSKq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVACIONES**: Hemos tenido numerosos problemas con esta extracci√≥n de PDFs para el organismo IPCC. Primero, intentamos extraer informes completos. Al ser muy largos, consum√≠amos toda nuestra memoria RAM de la cuenta gratuita, Colab colapsaba y reiniciaba sesi√≥n. Y tocaba volver a empezar. Claro eran demasiados archivos enormes procesados a la vez. De ah√≠, que optaramos por un *procesamiento incremental**, con el que poder liberar memoria.\n",
        "\n",
        "Intentamos hacerlo por cap√≠tulos y nos enfrentamos a varios desaf√≠os igualmente. Por un lado, algunos de los enlaces hab√≠an quedado obsoletos. Para AR6 y SREX las URLs son estables (no han cambiado desde hace a√±os); sin embargo, para SR15, SROCC y SRCCL las carpetas de nuestros enlaces ya no exist√≠an. IPCC reorganiz√≥ la web entre 2020 y 2023; as√≠ que justo esos informes se vieron afectados. En consecuencia, tuvimos que buscar las nuevas rutas y los nuevos nombres de archivo para esos 18 cap√≠tulos.\n",
        "\n",
        "Por √∫ltimo, y no menos importante, fue necesario incorporar al c√≥digo reanudaci√≥n autom√°tica, porque el proceso tarda entre 60-75 minutos. Ante la posibilidad de que Colab se reinicie pasado determinado tiempo, el pipeline continuar√° donde lo dej√≥ sin tener que volver a descargar los PDFs, procesarlos y guardar corpus si ya lo ha hecho antes, simplemente integrando una serie de checkpoints en los diferentes pasos.\n",
        "\n",
        "**Cada cap√≠tulo se procesa de forma incremental: se descarga, se lee p√°gina a p√°gina, se divide en segmentos y se guarda el progreso continuamente, permitiendo reanudar el proceso sin repetir trabajo si la sesi√≥n se interrumpe. Adem√°s, este enfoque libera memoria despu√©s de procesar cada p√°gina o bloque, evitando cargar el PDF completo en RAM y garantizando que el sistema pueda manejar documentos extensos incluso en entornos con recursos limitados como Google Colab.*"
      ],
      "metadata": {
        "id": "mxt2zF0-FtxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "IPCC Document Extractor - OPTIMIZADO PARA COLAB GRATUITO\n",
        "Versi√≥n con cap√≠tulos individuales y procesamiento incremental\n",
        "Consumo m√°ximo de RAM: ~3-4 GB (seguro para Colab gratuito)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Set, Tuple\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import gc\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "# Suprimir warnings molestos\n",
        "logging.getLogger('pdfminer').setLevel(logging.ERROR)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# INSTALACI√ìN DE DEPENDENCIAS\n",
        "# ============================================================================\n",
        "\n",
        "!pip install PyPDF2 pdfplumber requests tqdm -q\n",
        "\n",
        "\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CAT√ÅLOGO OPTIMIZADO - CAP√çTULOS INDIVIDUALES\n",
        "# ============================================================================\n",
        "\n",
        "IPCC_CHAPTERS_CATALOG = {\n",
        "    \"AR6_WG2\": {\n",
        "        \"name\": \"AR6 Working Group II (2022)\",\n",
        "        \"priority\": \"HIGH\",\n",
        "        \"base_url\": \"https://www.ipcc.ch/report/ar6/wg2/downloads/report/\",\n",
        "        \"chapters\": [\n",
        "            # Technical Summary y SPM (esenciales)\n",
        "            {\"file\": \"IPCC_AR6_WGII_TechnicalSummary.pdf\", \"title\": \"Technical Summary\", \"expected_docs\": 15},\n",
        "            {\"file\": \"IPCC_AR6_WGII_SummaryForPolicymakers.pdf\", \"title\": \"Summary for Policymakers\", \"expected_docs\": 8},\n",
        "\n",
        "            # Cap√≠tulos tem√°ticos clave (selecci√≥n estrat√©gica de los m√°s relevantes)\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter02.pdf\", \"title\": \"Chapter 2 - Terrestrial and Freshwater Ecosystems\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter03.pdf\", \"title\": \"Chapter 3 - Oceans and Coastal Ecosystems\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter04.pdf\", \"title\": \"Chapter 4 - Water\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter05.pdf\", \"title\": \"Chapter 5 - Food, Fibre and Livelihoods\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter06.pdf\", \"title\": \"Chapter 6 - Cities, Settlements and Infrastructure\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter07.pdf\", \"title\": \"Chapter 7 - Health, Wellbeing and Communities\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter08.pdf\", \"title\": \"Chapter 8 - Poverty, Livelihoods and Development\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter09.pdf\", \"title\": \"Chapter 9 - Africa\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter10.pdf\", \"title\": \"Chapter 10 - Asia\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter11.pdf\", \"title\": \"Chapter 11 - Australasia\", \"expected_docs\": 8},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter12.pdf\", \"title\": \"Chapter 12 - Central and South America\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter13.pdf\", \"title\": \"Chapter 13 - Europe\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter14.pdf\", \"title\": \"Chapter 14 - North America\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter15.pdf\", \"title\": \"Chapter 15 - Small Islands\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter16.pdf\", \"title\": \"Chapter 16 - Key Risks\", \"expected_docs\": 12},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter17.pdf\", \"title\": \"Chapter 17 - Decision Making\", \"expected_docs\": 10},\n",
        "            {\"file\": \"IPCC_AR6_WGII_Chapter18.pdf\", \"title\": \"Chapter 18 - Climate Resilient Development\", \"expected_docs\": 12},\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"SREX\": {\n",
        "        \"name\": \"Special Report on Extreme Events (2012)\",\n",
        "        \"priority\": \"HIGH\",\n",
        "        \"base_url\": \"https://www.ipcc.ch/site/assets/uploads/2018/03/\",\n",
        "        \"chapters\": [\n",
        "            {\"file\": \"SREX-Chap1_FINAL-1.pdf\", \"title\": \"Chapter 1 - Climate Extremes\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SREX-Chap2_FINAL-1.pdf\", \"title\": \"Chapter 2 - Determinants of Risk\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SREX-Chap3_FINAL-1.pdf\", \"title\": \"Chapter 3 - Changes in Extremes\", \"expected_docs\": 10},\n",
        "            {\"file\": \"SREX-Chap4_FINAL-1.pdf\", \"title\": \"Chapter 4 - Changes in Impacts\", \"expected_docs\": 10},\n",
        "            {\"file\": \"SREX-Chap5_FINAL-1.pdf\", \"title\": \"Chapter 5 - Managing Risks\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SREX-Chap6_FINAL-1.pdf\", \"title\": \"Chapter 6 - National Systems\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SREX-Chap7_FINAL-1.pdf\", \"title\": \"Chapter 7 - Managing Disaster Risks\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SREX-Chap8_FINAL-1.pdf\", \"title\": \"Chapter 8 - Climate Change Context\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SREX-Chap9_FINAL-1.pdf\", \"title\": \"Chapter 9 - Case Studies\", \"expected_docs\": 10},\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"SR15\": {\n",
        "        \"name\": \"Special Report on 1.5¬∞C (2018)\",\n",
        "        \"priority\": \"MEDIUM\",\n",
        "        \"base_url\": \"https://www.ipcc.ch/site/assets/uploads/sites/2/2022/06/\",\n",
        "        \"chapters\": [\n",
        "            {\"file\": \"SR15_Chapter_1_LR.pdf\", \"title\": \"Chapter 1 - Framing and Context\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SR15_Chapter_2_LR.pdf\", \"title\": \"Chapter 2 - Mitigation Pathways\", \"expected_docs\": 6},\n",
        "            {\"file\": \"SR15_Chapter_3_LR.pdf\", \"title\": \"Chapter 3 - Impacts of 1.5¬∞C\", \"expected_docs\": 10},\n",
        "            {\"file\": \"SR15_Chapter_4_LR.pdf\", \"title\": \"Chapter 4 - Strengthening Response\", \"expected_docs\": 8},\n",
        "            {\"file\": \"SR15_Chapter_5_HR.pdf\", \"title\": \"Chapter 5 - Sustainable Development\", \"expected_docs\": 8},\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"SROCC\": {\n",
        "        \"name\": \"Special Report on Ocean and Cryosphere (2019)\",\n",
        "        \"priority\": \"MEDIUM\",\n",
        "        \"base_url\": \"https://www.ipcc.ch/site/assets/uploads/sites/3/2022/03/\",\n",
        "        \"chapters\": [\n",
        "            {\"file\": \"03_SROCC_Ch01_FINAL.pdf\", \"title\": \"Chapter 1 - Framing\", \"expected_docs\": 6},\n",
        "            {\"file\": \"04_SROCC_Ch02_FINAL.pdf\", \"title\": \"Chapter 2 - High Mountain Areas\", \"expected_docs\": 8},\n",
        "            {\"file\": \"05_SROCC_Ch03_FINAL.pdf\", \"title\": \"Chapter 3 - Polar Regions\", \"expected_docs\": 8},\n",
        "            {\"file\": \"06_SROCC_Ch04_FINAL.pdf\", \"title\": \"Chapter 4 - Sea Level Rise\", \"expected_docs\": 10},\n",
        "            {\"file\": \"07_SROCC_Ch05_FINAL.pdf\", \"title\": \"Chapter 5 - Marine Ecosystems\", \"expected_docs\": 10},\n",
        "            {\"file\": \"08_SROCC_Ch06_FINAL.pdf\", \"title\": \"Chapter 6 - Extremes and Abrupt Changes\", \"expected_docs\": 8},\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"SRCCL\": {\n",
        "        \"name\": \"Special Report on Climate and Land (2019)\",\n",
        "        \"priority\": \"MEDIUM\",\n",
        "        \"base_url\": \"https://www.ipcc.ch/site/assets/uploads/sites/4/2020/05/\",\n",
        "        \"chapters\": [\n",
        "            {\"file\": \"Chapter-1_FINAL-1.pdf\", \"title\": \"Chapter 1 - Framing\", \"expected_docs\": 6},\n",
        "            {\"file\": \"Chapter-2_FINAL_updated-30-April.pdf\", \"title\": \"Chapter 2 - Land-Climate Interactions\", \"expected_docs\": 8},\n",
        "            {\"file\": \"Chapter-3_FINAL-1.pdf\", \"title\": \"Chapter 3 - Desertification\", \"expected_docs\": 10},\n",
        "            {\"file\": \"Chapter-4_FINAL-1.pdf\", \"title\": \"Chapter 4 - Land Degradation\", \"expected_docs\": 8},\n",
        "            {\"file\": \"Chapter-5_FINAL-1.pdf\", \"title\": \"Chapter 5 - Food Security\", \"expected_docs\": 10},\n",
        "            {\"file\": \"Chapter-6_FINAL-1.pdf\", \"title\": \"Chapter 6 - Interlinkages\", \"expected_docs\": 8},\n",
        "            {\"file\": \"Chapter-7_FINAL-1.pdf\", \"title\": \"Chapter 7 - Risk Management\", \"expected_docs\": 8},\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TAXONOM√çA (tu taxonom√≠a completa)\n",
        "# ============================================================================\n",
        "\n",
        "IPCC_TAXONOMY = {\n",
        "    'hazards': {\n",
        "        'heat': ['heat', 'heatwave', 'heat wave', 'extreme temperature', 'thermal stress',\n",
        "                'hot extremes', 'warming', 'high temperature'],\n",
        "        'flood': ['flood', 'flooding', 'inundation', 'pluvial', 'fluvial', 'riverine',\n",
        "                 'coastal flood', 'flash flood', 'storm surge', 'sea level rise'],\n",
        "        'drought': ['drought', 'water scarcity', 'water stress', 'aridity', 'dry spell',\n",
        "                   'hydrological drought', 'agricultural drought', 'water shortage'],\n",
        "        'storm': ['tropical cyclone', 'hurricane', 'typhoon', 'storm', 'wind extremes',\n",
        "                 'extratropical cyclone', 'severe weather'],\n",
        "        'compound': ['compound event', 'concurrent', 'cascading', 'multiple hazard',\n",
        "                    'combined risk', 'interacting'],\n",
        "        'wildfire': ['wildfire', 'fire', 'fire weather', 'fire risk'],\n",
        "        'cold': ['cold extreme', 'frost', 'freeze', 'ice', 'snow'],\n",
        "        'landslide': ['landslide', 'mudslide', 'mass movement', 'slope instability'],\n",
        "        'coastal': ['coastal erosion', 'shoreline retreat', 'coastal hazard']\n",
        "    },\n",
        "\n",
        "    'adaptation_measures': {\n",
        "        'nature_based': ['nature-based solution', 'nbs', 'ecosystem-based', 'green infrastructure',\n",
        "                        'wetland', 'mangrove', 'forest', 'restoration', 'conservation'],\n",
        "        'infrastructure': ['infrastructure', 'sea wall', 'levee', 'barrier', 'dike',\n",
        "                          'drainage', 'engineered', 'hard adaptation'],\n",
        "        'planning': ['adaptation plan', 'planning', 'policy', 'governance', 'institutional',\n",
        "                    'regulation', 'zoning', 'land use'],\n",
        "        'early_warning': ['early warning', 'forecasting', 'monitoring', 'climate service',\n",
        "                         'risk assessment', 'vulnerability assessment'],\n",
        "        'water_management': ['irrigation', 'water management', 'water storage', 'rainwater',\n",
        "                            'water efficiency', 'demand management'],\n",
        "        'agriculture': ['drought-resistant', 'crop adaptation', 'climate-smart agriculture',\n",
        "                       'agricultural adaptation', 'crop diversification'],\n",
        "        'financial': ['insurance', 'climate finance', 'adaptation finance', 'funding',\n",
        "                     'investment', 'economic instrument']\n",
        "    },\n",
        "\n",
        "    'sectors': {\n",
        "        'urban': ['urban', 'city', 'cities', 'municipal', 'settlement'],\n",
        "        'health': ['health', 'mortality', 'morbidity', 'disease', 'public health'],\n",
        "        'water': ['water supply', 'water resource', 'water system', 'freshwater'],\n",
        "        'agriculture': ['agriculture', 'crop', 'food security', 'farming', 'livestock'],\n",
        "        'coastal': ['coastal', 'coast', 'marine', 'ocean', 'shoreline'],\n",
        "        'infrastructure': ['infrastructure', 'transport', 'energy', 'critical infrastructure'],\n",
        "        'ecosystem': ['ecosystem', 'biodiversity', 'species', 'habitat', 'ecological']\n",
        "    },\n",
        "\n",
        "    'impacts': {\n",
        "        'health_impacts': ['mortality', 'death', 'morbidity', 'illness', 'health risk',\n",
        "                          'heat-related', 'disease burden'],\n",
        "        'economic_impacts': ['economic loss', 'damage', 'cost', 'gdp', 'productivity loss',\n",
        "                            'economic impact'],\n",
        "        'social_impacts': ['displacement', 'migration', 'livelihood', 'poverty', 'inequality',\n",
        "                          'vulnerable', 'community'],\n",
        "        'environmental_impacts': ['ecosystem degradation', 'habitat loss', 'biodiversity loss',\n",
        "                                 'species extinction', 'water quality']\n",
        "    },\n",
        "\n",
        "    'concepts': {\n",
        "        'adaptation': ['adaptation', 'adaptive capacity', 'resilience', 'vulnerability',\n",
        "                      'exposure', 'sensitivity', 'coping capacity'],\n",
        "        'risk': ['climate risk', 'risk assessment', 'disaster risk reduction', 'risk management',\n",
        "                'hazard', 'impact', 'consequence'],\n",
        "        'transformation': ['transformation', 'transformational adaptation', 'systemic change',\n",
        "                          'paradigm shift', 'maladaptation']\n",
        "    },\n",
        "\n",
        "    'regions': {\n",
        "        'vulnerable': ['small island', 'sids', 'developing countries', 'least developed',\n",
        "                      'vulnerable regions', 'low-income', 'global south'],\n",
        "        'geographic': ['africa', 'asia', 'europe', 'americas', 'mediterranean', 'arctic',\n",
        "                      'tropics', 'arid', 'semi-arid', 'coastal regions', 'mountains']\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CLASE PRINCIPAL - OPTIMIZADA PARA RAM\n",
        "# ============================================================================\n",
        "\n",
        "class IPCCExtractorOptimized:\n",
        "    \"\"\"\n",
        "    Extractor optimizado con procesamiento incremental\n",
        "    M√°ximo consumo de RAM: ~3-4 GB\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dir: str = \"./ipcc_data\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.pdfs_dir = self.output_dir / \"pdfs\"\n",
        "        self.pdfs_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.segments_dir = self.output_dir / \"segments\"\n",
        "        self.segments_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.processed_files = []\n",
        "\n",
        "    def check_existing_progress(self):\n",
        "        \"\"\"\n",
        "        Comprueba qu√© partes del pipeline ya est√°n completadas.\n",
        "        Devuelve un diccionario con:\n",
        "        - pdfs: si los PDFs ya est√°n descargados\n",
        "        - segments: si ya existen segmentos procesados\n",
        "        - corpus: si ya existe el corpus final\n",
        "        \"\"\"\n",
        "        status = {\n",
        "            \"pdfs\": False,\n",
        "            \"segments\": False,\n",
        "            \"corpus\": False\n",
        "        }\n",
        "\n",
        "        pdf_dir = self.pdfs_dir\n",
        "        seg_dir = self.segments_dir\n",
        "        corpus_file = self.output_dir / \"ipcc_corpus.json\"\n",
        "\n",
        "        # PDFs descargados\n",
        "        if pdf_dir.exists() and any(pdf_dir.glob(\"*.pdf\")):\n",
        "            status[\"pdfs\"] = True\n",
        "\n",
        "        # Segmentos procesados\n",
        "        if seg_dir.exists() and any(seg_dir.glob(\"*_segments.json\")):\n",
        "            status[\"segments\"] = True\n",
        "\n",
        "        # Corpus final\n",
        "        if corpus_file.exists():\n",
        "           status[\"corpus\"] = True\n",
        "\n",
        "        return status\n",
        "\n",
        "\n",
        "    def download_chapter(self, base_url: str, chapter_info: Dict, report_key: str) -> bool:\n",
        "        \"\"\"Descarga un cap√≠tulo individual\"\"\"\n",
        "        filename = f\"{report_key}_{chapter_info['file']}\"\n",
        "        filepath = self.pdfs_dir / filename\n",
        "\n",
        "        if filepath.exists():\n",
        "            size_mb = filepath.stat().st_size / 1024 / 1024\n",
        "            print(f\"   ‚úì Existe: {filename} ({size_mb:.1f} MB)\")\n",
        "            return True\n",
        "\n",
        "        url = base_url + chapter_info['file']\n",
        "\n",
        "        try:\n",
        "            print(f\"   üì• Descargando: {chapter_info['title']}\")\n",
        "            response = requests.get(url, stream=True, timeout=120)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                with tqdm(total=total_size, unit='B', unit_scale=True,\n",
        "                         desc=f\"      {filename[:40]}\", leave=False) as pbar:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                        pbar.update(len(chunk))\n",
        "\n",
        "            size_mb = filepath.stat().st_size / 1024 / 1024\n",
        "            print(f\"   ‚úì Descargado: {filename} ({size_mb:.1f} MB)\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚úó Error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def download_all_chapters(self):\n",
        "        \"\"\"Descarga todos los cap√≠tulos del cat√°logo\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üì• DESCARGANDO CAP√çTULOS DEL IPCC\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        total_chapters = sum(len(r['chapters']) for r in IPCC_CHAPTERS_CATALOG.values())\n",
        "        print(f\"Total de cap√≠tulos a descargar: {total_chapters}\\n\")\n",
        "\n",
        "        for report_key, report_data in IPCC_CHAPTERS_CATALOG.items():\n",
        "            print(f\"\\nüìÑ {report_data['name']}\")\n",
        "            print(f\"   Prioridad: {report_data['priority']}\")\n",
        "            print(f\"   Cap√≠tulos: {len(report_data['chapters'])}\")\n",
        "\n",
        "            for chapter in report_data['chapters']:\n",
        "                self.download_chapter(report_data['base_url'], chapter, report_key)\n",
        "                time.sleep(0.5)  # Rate limiting suave\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path: Path) -> str:\n",
        "        \"\"\"Extrae texto de PDF (optimizado)\"\"\"\n",
        "        text = \"\"\n",
        "\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                total_pages = len(pdf.pages)\n",
        "\n",
        "                for page in tqdm(pdf.pages, desc=f\"      Extrayendo\", leave=False):\n",
        "                    try:\n",
        "                        page_text = page.extract_text()\n",
        "                        if page_text:\n",
        "                            text += page_text + \"\\n\\n\"\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "            if not text.strip():\n",
        "                # Fallback a PyPDF2\n",
        "                with open(pdf_path, 'rb') as f:\n",
        "                    pdf_reader = PyPDF2.PdfReader(f)\n",
        "                    for page in pdf_reader.pages:\n",
        "                        try:\n",
        "                            text += page.extract_text() + \"\\n\\n\"\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ö†Ô∏è  Error: {e}\")\n",
        "\n",
        "        return text\n",
        "\n",
        "    def segment_text(self, text: str, max_chunk_size: int = 5000) -> List[str]:\n",
        "        \"\"\"\n",
        "        Segmenta texto en chunks manejables\n",
        "        ~5000 palabras por chunk (tama√±o √≥ptimo para embeddings)\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(0, len(words), max_chunk_size):\n",
        "            chunk = ' '.join(words[i:i+max_chunk_size])\n",
        "            if len(chunk) > 500:  # M√≠nimo 500 caracteres\n",
        "                chunks.append(chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def score_segment(self, text: str) -> Tuple[float, Dict]:\n",
        "        \"\"\"Punt√∫a un segmento seg√∫n taxonom√≠a\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        matches = {\n",
        "            'hazards': set(),\n",
        "            'adaptation_measures': set(),\n",
        "            'sectors': set(),\n",
        "            'impacts': set(),\n",
        "            'concepts': set(),\n",
        "            'regions': set()\n",
        "        }\n",
        "\n",
        "        # Buscar coincidencias\n",
        "        for category, subcategories in IPCC_TAXONOMY.items():\n",
        "            for subcat, terms in subcategories.items():\n",
        "                for term in terms:\n",
        "                    if term.lower() in text_lower:\n",
        "                        matches[category].add(subcat)\n",
        "                        break\n",
        "\n",
        "        # Calcular score\n",
        "        score = (\n",
        "            len(matches['hazards']) * 3.0 +\n",
        "            len(matches['adaptation_measures']) * 2.5 +\n",
        "            len(matches['impacts']) * 2.0 +\n",
        "            len(matches['sectors']) * 1.5 +\n",
        "            len(matches['concepts']) * 1.0 +\n",
        "            len(matches['regions']) * 1.0\n",
        "        )\n",
        "\n",
        "        # Bonus por diversidad\n",
        "        if len(matches['hazards']) >= 2:\n",
        "            score += 2.0\n",
        "        if len(matches['adaptation_measures']) >= 2:\n",
        "            score += 1.5\n",
        "\n",
        "        return score, {k: list(v) for k, v in matches.items()}\n",
        "\n",
        "    def process_single_pdf(self, pdf_path: Path, report_key: str, chapter_title: str):\n",
        "        \"\"\"\n",
        "        Procesa UN SOLO PDF y guarda resultados inmediatamente\n",
        "        CLAVE para gesti√≥n de RAM\n",
        "        \"\"\"\n",
        "        print(f\"\\nüìñ Procesando: {pdf_path.name}\")\n",
        "\n",
        "        # Extraer texto\n",
        "        text = self.extract_text_from_pdf(pdf_path)\n",
        "\n",
        "        if not text or len(text) < 500:\n",
        "            print(f\"   ‚ö†Ô∏è  Texto insuficiente\")\n",
        "            return\n",
        "\n",
        "        print(f\"   ‚úì Extra√≠dos {len(text)} caracteres\")\n",
        "\n",
        "        # Segmentar\n",
        "        chunks = self.segment_text(text, max_chunk_size=5000)\n",
        "        print(f\"   ‚úì {len(chunks)} segmentos creados\")\n",
        "\n",
        "        # Puntuar y guardar\n",
        "        segments = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            score, taxonomy = self.score_segment(chunk)\n",
        "\n",
        "            if score >= 1.0:  # Umbral m√≠nimo para guardar\n",
        "                segment = {\n",
        "                    'source': 'ipcc',\n",
        "                    'source_id': f\"{report_key}_{pdf_path.stem}_{i}\",\n",
        "                    'title': f\"{chapter_title} - Segment {i+1}\",\n",
        "                    'text': chunk[:2000],  # Abstract\n",
        "                    'full_text': chunk,\n",
        "                    'report': report_key,\n",
        "                    'chapter': chapter_title,\n",
        "                    'score': score,\n",
        "                    'matched_taxonomy': taxonomy\n",
        "                }\n",
        "                segments.append(segment)\n",
        "\n",
        "        # GUARDAR INMEDIATAMENTE (libera RAM)\n",
        "        if segments:\n",
        "            output_file = self.segments_dir / f\"{pdf_path.stem}_segments.json\"\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(segments, f, ensure_ascii=False)\n",
        "\n",
        "            print(f\"   üíæ {len(segments)} segmentos guardados ‚Üí {output_file.name}\")\n",
        "            self.processed_files.append(output_file)\n",
        "\n",
        "        # LIBERAR MEMORIA\n",
        "        del text, chunks, segments\n",
        "        gc.collect()\n",
        "\n",
        "    def process_all_pdfs(self):\n",
        "        \"\"\"Procesa todos los PDFs uno a uno (incremental)\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìÑ PROCESANDO CAP√çTULOS\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "        pdf_files = sorted(list(self.pdfs_dir.glob(\"*.pdf\")))\n",
        "\n",
        "        if not pdf_files:\n",
        "            print(\"‚ö†Ô∏è  No se encontraron PDFs\")\n",
        "            return\n",
        "\n",
        "        print(f\"Total de archivos a procesar: {len(pdf_files)}\\n\")\n",
        "\n",
        "        for pdf_file in tqdm(pdf_files, desc=\"Procesando cap√≠tulos\"):\n",
        "            # Identificar report y cap√≠tulo\n",
        "            parts = pdf_file.stem.split('_', 1)\n",
        "            report_key = parts[0] if parts else \"UNKNOWN\"\n",
        "\n",
        "            # Buscar t√≠tulo del cap√≠tulo\n",
        "            chapter_title = pdf_file.stem\n",
        "            for report_data in IPCC_CHAPTERS_CATALOG.values():\n",
        "                for ch in report_data['chapters']:\n",
        "                    if ch['file'] in pdf_file.name:\n",
        "                        chapter_title = ch['title']\n",
        "                        break\n",
        "\n",
        "            self.process_single_pdf(pdf_file, report_key, chapter_title)\n",
        "\n",
        "        print(f\"\\n‚úÖ {len(self.processed_files)} archivos procesados\")\n",
        "\n",
        "    def select_top_segments(self, n: int = 400, min_score: float = 2.5) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Carga scores de todos los segmentos y selecciona los mejores\n",
        "        Solo carga scores, no texto completo (RAM eficiente)\n",
        "        \"\"\"\n",
        "        print(f\"\\nüéØ Seleccionando top {n} segmentos...\")\n",
        "\n",
        "        # Cargar solo scores (no full_text)\n",
        "        all_segments = []\n",
        "\n",
        "        for segment_file in tqdm(self.processed_files, desc=\"Cargando scores\"):\n",
        "            with open(segment_file, 'r', encoding='utf-8') as f:\n",
        "                segments = json.load(f)\n",
        "                # Remover full_text para ahorrar RAM\n",
        "                for seg in segments:\n",
        "                    seg_light = {k: v for k, v in seg.items() if k != 'full_text'}\n",
        "                    seg_light['_file'] = segment_file  # Guardar referencia\n",
        "                    all_segments.append(seg_light)\n",
        "\n",
        "        print(f\"   Total de segmentos: {len(all_segments)}\")\n",
        "\n",
        "        # Filtrar por score\n",
        "        qualified = [s for s in all_segments if s['score'] >= min_score]\n",
        "        print(f\"   Calificados (score >= {min_score}): {len(qualified)}\")\n",
        "\n",
        "        if len(qualified) < n:\n",
        "            new_threshold = min_score * 0.7\n",
        "            print(f\"   Ajustando umbral a {new_threshold:.1f}\")\n",
        "            qualified = [s for s in all_segments if s['score'] >= new_threshold]\n",
        "\n",
        "        # Ordenar y seleccionar con diversidad\n",
        "        sorted_segments = sorted(qualified, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "        selected = []\n",
        "        coverage = defaultdict(int)\n",
        "\n",
        "        for seg in sorted_segments:\n",
        "            if len(selected) >= n:\n",
        "                break\n",
        "\n",
        "            report = seg['report']\n",
        "            if coverage[report] >= n * 0.35:  # M√°x 35% por reporte\n",
        "                continue\n",
        "\n",
        "            selected.append(seg)\n",
        "            coverage[report] += 1\n",
        "\n",
        "        print(f\"\\n‚úÖ Seleccionados {len(selected)} segmentos\")\n",
        "        print(\"\\nüìä Distribuci√≥n:\")\n",
        "        for report, count in sorted(coverage.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"   {report}: {count} ({count/len(selected)*100:.1f}%)\")\n",
        "\n",
        "        return selected\n",
        "\n",
        "    def load_full_segments(self, selected_light: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Carga el texto completo solo de los segmentos seleccionados\"\"\"\n",
        "        print(f\"\\nüì• Cargando texto completo de {len(selected_light)} segmentos...\")\n",
        "\n",
        "        # Agrupar por archivo para cargar eficientemente\n",
        "        by_file = defaultdict(list)\n",
        "        for seg in selected_light:\n",
        "            by_file[seg['_file']].append(seg['source_id'])\n",
        "\n",
        "        full_segments = []\n",
        "\n",
        "        for file_path, source_ids in tqdm(by_file.items(), desc=\"Cargando texto\"):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                all_segs = json.load(f)\n",
        "                for seg in all_segs:\n",
        "                    if seg['source_id'] in source_ids:\n",
        "                        full_segments.append(seg)\n",
        "\n",
        "        return full_segments\n",
        "\n",
        "    def save_corpus(self, segments: List[Dict], filename: str = \"ipcc_corpus.json\"):\n",
        "        \"\"\"Guarda el corpus final\"\"\"\n",
        "        output_path = self.output_dir / filename\n",
        "\n",
        "        # A√±adir a√±o\n",
        "        for seg in segments:\n",
        "            seg['year'] = self._extract_year(seg['report'])\n",
        "\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(segments, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\nüíæ Corpus guardado: {output_path}\")\n",
        "\n",
        "        # Generar reporte\n",
        "        self._save_report(segments)\n",
        "\n",
        "        return segments\n",
        "\n",
        "    def _extract_year(self, report_key: str) -> int:\n",
        "        \"\"\"Extrae a√±o del reporte\"\"\"\n",
        "        year_map = {\n",
        "            'AR6_WG2': 2022,\n",
        "            'SREX': 2012,\n",
        "            'SR15': 2018,\n",
        "            'SROCC': 2019,\n",
        "            'SRCCL': 2019,\n",
        "            'AR5_WG2': 2014\n",
        "        }\n",
        "        return year_map.get(report_key, 2020)\n",
        "\n",
        "    def _save_report(self, segments: List[Dict]):\n",
        "        \"\"\"Genera reporte de an√°lisis\"\"\"\n",
        "        report_path = self.output_dir / \"ipcc_selection_report.txt\"\n",
        "\n",
        "        with open(report_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\"*70 + \"\\n\")\n",
        "            f.write(\"REPORTE DE SELECCI√ìN - IPCC CORPUS\\n\")\n",
        "            f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "            f.write(f\"Total de segmentos: {len(segments)}\\n\")\n",
        "            f.write(f\"M√©todo: Cap√≠tulos individuales + Procesamiento incremental\\n\")\n",
        "            f.write(f\"Consumo m√°ximo de RAM: ~3-4 GB\\n\\n\")\n",
        "\n",
        "            # Estad√≠sticas de taxonom√≠a\n",
        "            all_hazards = defaultdict(int)\n",
        "            all_adaptation_measures = defaultdict(int)\n",
        "            all_sectors = defaultdict(int)\n",
        "\n",
        "            for seg in segments:\n",
        "                for h in seg['matched_taxonomy']['hazards']:\n",
        "                    all_hazards[h] += 1\n",
        "                for m in seg['matched_taxonomy']['adaptation_measures']:\n",
        "                    all_adaptation_measures[m] += 1\n",
        "                for s in seg['matched_taxonomy']['sectors']:\n",
        "                    all_sectors[s] += 1\n",
        "\n",
        "            f.write(\"COBERTURA DE TAXONOM√çA:\\n\")\n",
        "            f.write(\"-\"*70 + \"\\n\")\n",
        "            f.write(f\"\\nHAZARDS ({len(all_hazards)} tipos):\\n\")\n",
        "            for h, count in sorted(all_hazards.items(), key=lambda x: x[1], reverse=True):\n",
        "                f.write(f\"  {h}: {count} segmentos\\n\")\n",
        "\n",
        "            f.write(f\"\\nADAPTATION MEASURES ({len(all_adaptation_measures)} tipos):\\n\")\n",
        "            for m, count in sorted(all_adaptation_measures.items(), key=lambda x: x[1], reverse=True):\n",
        "                f.write(f\"  {m}: {count} segmentos\\n\")\n",
        "\n",
        "            f.write(f\"\\nSECTORS ({len(all_sectors)} tipos):\\n\")\n",
        "            for s, count in sorted(all_sectors.items(), key=lambda x: x[1], reverse=True):\n",
        "                f.write(f\"  {s}: {count} segmentos\\n\")\n",
        "\n",
        "            # Distribuci√≥n por reporte\n",
        "            by_report = defaultdict(int)\n",
        "            for seg in segments:\n",
        "                by_report[seg['report']] += 1\n",
        "\n",
        "            f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "            f.write(\"DISTRIBUCI√ìN POR REPORTE:\\n\")\n",
        "            f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "            for report, count in sorted(by_report.items(), key=lambda x: x[1], reverse=True):\n",
        "                pct = count / len(segments) * 100\n",
        "                f.write(f\"{report}: {count} segmentos ({pct:.1f}%)\\n\")\n",
        "\n",
        "            # Top 10\n",
        "            f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "            f.write(\"TOP 10 SEGMENTOS:\\n\")\n",
        "            f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "            top_10 = sorted(segments, key=lambda x: x['score'], reverse=True)[:10]\n",
        "            for i, seg in enumerate(top_10, 1):\n",
        "                f.write(f\"{i}. {seg['title']}\\n\")\n",
        "                f.write(f\"   Score: {seg['score']:.2f}\\n\")\n",
        "                f.write(f\"   Hazards: {', '.join(seg['matched_taxonomy']['hazards'])}\\n\")\n",
        "                f.write(f\"   Adaptation measures: {', '.join(seg['matched_taxonomy']['adaptation_measures'])}\\n\\n\")\n",
        "\n",
        "        print(f\"üìÑ Reporte guardado: {report_path}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PIPELINE COMPLETO\n",
        "# ============================================================================\n",
        "\n",
        "def run_optimized_pipeline(n_documents: int = 400):\n",
        "    \"\"\"\n",
        "    Pipeline optimizado para Colab con reanudaci√≥n autom√°tica.\n",
        "    Si la sesi√≥n se reinicia, contin√∫a desde el √∫ltimo paso completado.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üåç IPCC EXTRACTOR - REANUDACI√ìN AUTOM√ÅTICA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nüìä Caracter√≠sticas:\")\n",
        "    print(\" ‚Ä¢ Cap√≠tulos individuales (40-50 archivos)\")\n",
        "    print(\" ‚Ä¢ Procesamiento incremental\")\n",
        "    print(\" ‚Ä¢ Consumo RAM: ~3-4 GB\")\n",
        "    print(\" ‚Ä¢ Compatible con Colab gratuito\")\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "    extractor = IPCCExtractorOptimized(output_dir=\"./ipcc_data\")\n",
        "    status = extractor.check_existing_progress()\n",
        "\n",
        "    print(\"\\nüìå Estado detectado:\")\n",
        "    print(f\"   ‚Ä¢ PDFs descargados:     {status['pdfs']}\")\n",
        "    print(f\"   ‚Ä¢ Segmentos procesados: {status['segments']}\")\n",
        "    print(f\"   ‚Ä¢ Corpus final:         {status['corpus']}\")\n",
        "\n",
        "    # PASO 1: Descargar PDFs\n",
        "    if not status[\"pdfs\"]:\n",
        "        print(\"\\n[PASO 1/4] Descargando cap√≠tulos...\")\n",
        "        extractor.download_all_chapters()\n",
        "    else:\n",
        "        print(\"\\n‚úîÔ∏è PDFs ya descargados. Saltando paso 1.\")\n",
        "\n",
        "    # PASO 2: Procesar PDFs\n",
        "    if not status[\"segments\"]:\n",
        "        print(\"\\n[PASO 2/4] Procesando cap√≠tulos...\")\n",
        "        extractor.process_all_pdfs()\n",
        "    else:\n",
        "        print(\"\\n‚úîÔ∏è Segmentos ya generados. Saltando paso 2.\")\n",
        "\n",
        "    # PASO 3: Seleccionar mejores segmentos\n",
        "    print(\"\\n[PASO 3/4] Seleccionando segmentos...\")\n",
        "    selected_light = extractor.select_top_segments(n=n_documents, min_score=2.5)\n",
        "\n",
        "    # PASO 4: Generar corpus final\n",
        "    if not status[\"corpus\"]:\n",
        "        print(\"\\n[PASO 4/4] Generando corpus final...\")\n",
        "        full_segments = extractor.load_full_segments(selected_light)\n",
        "        corpus = extractor.save_corpus(full_segments)\n",
        "    else:\n",
        "        print(\"\\n‚úîÔ∏è Corpus ya existe. Cargando archivo existente...\")\n",
        "        with open(\"./ipcc_data/ipcc_corpus.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "            corpus = json.load(f)\n",
        "\n",
        "    # ============================\n",
        "    # PRINTS FINALES COMPLETOS\n",
        "    # ============================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ PIPELINE COMPLETADO\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüìä {len(corpus)} documentos listos\")\n",
        "\n",
        "    print(\"\\nüìÅ Archivos generados:\")\n",
        "    print(\"   ‚Ä¢ ipcc_data/ipcc_corpus.json\")\n",
        "    print(\"   ‚Ä¢ ipcc_data/ipcc_selection_report.txt\")\n",
        "    print(\"   ‚Ä¢ ipcc_data/segments/ (segmentos intermedios)\")\n",
        "    print(\"   ‚Ä¢ ipcc_data/pdfs/ (cap√≠tulos descargados)\")\n",
        "\n",
        "    # Estad√≠sticas finales\n",
        "    print(\"\\nüìà Estad√≠sticas:\")\n",
        "    by_report = defaultdict(int)\n",
        "    for seg in corpus:\n",
        "        by_report[seg['report']] += 1\n",
        "\n",
        "    for report, count in sorted(by_report.items(), key=lambda x: x[1], reverse=True):\n",
        "        pct = count / len(corpus) * 100\n",
        "        print(f\"   {report}: {count} docs ({pct:.1f}%)\")\n",
        "\n",
        "    return corpus\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# EJECUCI√ìN\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar pipeline optimizado\n",
        "    # Tiempo estimado: 60-75 minutos\n",
        "    # RAM m√°xima: ~3-4 GB (seguro para Colab gratuito)\n",
        "\n",
        "    corpus = run_optimized_pipeline(n_documents=400)"
      ],
      "metadata": {
        "id": "T-pWKs1h0z94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "6ff87966c4314b7c8806cbf1acfe3903",
            "605bb1868b7e49c5bd111ecffa6d2f10",
            "758d2193fafc4c239e9d629447744b0e",
            "98fe04f35e6c4776a8dca2103f0d004a",
            "cb71e9946c304f78b96621860adb1d65",
            "3f5aa13ad51a44ba8cfda740d731caf1",
            "e2c67d678fe844c6a9e32eb1f856b95f",
            "29d9215993be4bbc871e00bd5a749cc1",
            "7a82a932f80747cbb968acfe4c72709c",
            "f540b7c8c7bb436e8d319887c81bb305",
            "ba2831acdad744cea56586bd8830d21e"
          ]
        },
        "outputId": "ffcb91cd-885f-406f-cc84-52d2cc36a07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üåç IPCC EXTRACTOR - REANUDACI√ìN AUTOM√ÅTICA\n",
            "======================================================================\n",
            "\n",
            "üìä Caracter√≠sticas:\n",
            " ‚Ä¢ Cap√≠tulos individuales (40-50 archivos)\n",
            " ‚Ä¢ Procesamiento incremental\n",
            " ‚Ä¢ Consumo RAM: ~3-4 GB\n",
            " ‚Ä¢ Compatible con Colab gratuito\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "üìå Estado detectado:\n",
            "   ‚Ä¢ PDFs descargados:     True\n",
            "   ‚Ä¢ Segmentos procesados: True\n",
            "   ‚Ä¢ Corpus final:         True\n",
            "\n",
            "‚úîÔ∏è PDFs ya descargados. Saltando paso 1.\n",
            "\n",
            "‚úîÔ∏è Segmentos ya generados. Saltando paso 2.\n",
            "\n",
            "[PASO 3/4] Seleccionando segmentos...\n",
            "\n",
            "üéØ Seleccionando top 400 segmentos...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Cargando scores: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ff87966c4314b7c8806cbf1acfe3903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Total de segmentos: 0\n",
            "   Calificados (score >= 2.5): 0\n",
            "   Ajustando umbral a 1.8\n",
            "\n",
            "‚úÖ Seleccionados 0 segmentos\n",
            "\n",
            "üìä Distribuci√≥n:\n",
            "\n",
            "‚úîÔ∏è Corpus ya existe. Cargando archivo existente...\n",
            "\n",
            "======================================================================\n",
            "‚úÖ PIPELINE COMPLETADO\n",
            "======================================================================\n",
            "\n",
            "üìä 400 documentos listos\n",
            "\n",
            "üìÅ Archivos generados:\n",
            "   ‚Ä¢ ipcc_data/ipcc_corpus.json\n",
            "   ‚Ä¢ ipcc_data/ipcc_selection_report.txt\n",
            "   ‚Ä¢ ipcc_data/segments/ (segmentos intermedios)\n",
            "   ‚Ä¢ ipcc_data/pdfs/ (cap√≠tulos descargados)\n",
            "\n",
            "üìà Estad√≠sticas:\n",
            "   AR6: 140 docs (35.0%)\n",
            "   SRCCL: 103 docs (25.8%)\n",
            "   SROCC: 56 docs (14.0%)\n",
            "   SREX: 55 docs (13.8%)\n",
            "   SR15: 46 docs (11.5%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ipcc_pdfs.zip ipcc_data/pdfs\n",
        "!zip -r ipcc_segments.zip ipcc_data/segments\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGDpFgzajTSh",
        "outputId": "20f30729-0ba2-4649-e842-1a22e6c05378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: ipcc_data/pdfs/ (stored 0%)\n",
            "  adding: ipcc_data/pdfs/SROCC_06_SROCC_Ch04_FINAL.pdf (deflated 5%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter10.pdf (deflated 11%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter12.pdf (deflated 15%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter05.pdf (deflated 14%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-3_FINAL-1.pdf (deflated 7%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap6_FINAL-1.pdf (deflated 25%)\n",
            "  adding: ipcc_data/pdfs/SROCC_04_SROCC_Ch02_FINAL.pdf (deflated 6%)\n",
            "  adding: ipcc_data/pdfs/SR15_SR15_Chapter_5_HR.pdf (deflated 15%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter14.pdf (deflated 6%)\n",
            "  adding: ipcc_data/pdfs/SR15_SR15_Chapter_1_LR.pdf (deflated 20%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap4_FINAL-1.pdf (deflated 7%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-1_FINAL-1.pdf (deflated 11%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap8_FINAL-1.pdf (deflated 32%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_TechnicalSummary.pdf (deflated 28%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap3_FINAL-1.pdf (deflated 3%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap2_FINAL-1.pdf (deflated 28%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter17.pdf (deflated 35%)\n",
            "  adding: ipcc_data/pdfs/SROCC_03_SROCC_Ch01_FINAL.pdf (deflated 6%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-7_FINAL-1.pdf (deflated 9%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap5_FINAL-1.pdf (deflated 22%)\n",
            "  adding: ipcc_data/pdfs/SR15_SR15_Chapter_4_LR.pdf (deflated 32%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter16.pdf (deflated 26%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter11.pdf (deflated 29%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter04.pdf (deflated 9%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter18.pdf (deflated 21%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter07.pdf (deflated 27%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter09.pdf (deflated 10%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter02.pdf (deflated 33%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-6_FINAL-1.pdf (deflated 4%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-5_FINAL-1.pdf (deflated 7%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter03.pdf (deflated 14%)\n",
            "  adding: ipcc_data/pdfs/SROCC_08_SROCC_Ch06_FINAL.pdf (deflated 4%)\n",
            "  adding: ipcc_data/pdfs/SROCC_07_SROCC_Ch05_FINAL.pdf (deflated 3%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-2_FINAL_updated-30-April.pdf (deflated 10%)\n",
            "  adding: ipcc_data/pdfs/SROCC_05_SROCC_Ch03_FINAL.pdf (deflated 6%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap9_FINAL-1.pdf (deflated 35%)\n",
            "  adding: ipcc_data/pdfs/SR15_SR15_Chapter_3_LR.pdf (deflated 10%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter15.pdf (deflated 17%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap7_FINAL-1.pdf (deflated 40%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_SummaryForPolicymakers.pdf (deflated 40%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter13.pdf (deflated 13%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter06.pdf (deflated 21%)\n",
            "  adding: ipcc_data/pdfs/SREX_SREX-Chap1_FINAL-1.pdf (deflated 25%)\n",
            "  adding: ipcc_data/pdfs/AR6_WG2_IPCC_AR6_WGII_Chapter08.pdf (deflated 14%)\n",
            "  adding: ipcc_data/pdfs/SR15_SR15_Chapter_2_LR.pdf (deflated 16%)\n",
            "  adding: ipcc_data/pdfs/SRCCL_Chapter-4_FINAL-1.pdf (deflated 9%)\n",
            "  adding: ipcc_data/segments/ (stored 0%)\n",
            "  adding: ipcc_data/segments/SROCC_08_SROCC_Ch06_FINAL_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SR15_SR15_Chapter_5_HR_segments.json (deflated 69%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter10_segments.json (deflated 66%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap3_FINAL-1_segments.json (deflated 74%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_TechnicalSummary_segments.json (deflated 71%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-7_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter17_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter15_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter11_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap9_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap5_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SROCC_06_SROCC_Ch04_FINAL_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-5_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter07_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap7_FINAL-1_segments.json (deflated 69%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter18_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter08_segments.json (deflated 69%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter05_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap2_FINAL-1_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-1_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter16_segments.json (deflated 69%)\n",
            "  adding: ipcc_data/segments/SROCC_07_SROCC_Ch05_FINAL_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap1_FINAL-1_segments.json (deflated 69%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-6_FINAL-1_segments.json (deflated 71%)\n",
            "  adding: ipcc_data/segments/SR15_SR15_Chapter_2_LR_segments.json (deflated 71%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-2_FINAL_updated-30-April_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SROCC_03_SROCC_Ch01_FINAL_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-4_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter14_segments.json (deflated 66%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter13_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap4_FINAL-1_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap8_FINAL-1_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter12_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter06_segments.json (deflated 66%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter04_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter09_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SR15_SR15_Chapter_3_LR_segments.json (deflated 70%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter03_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/SR15_SR15_Chapter_4_LR_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SROCC_05_SROCC_Ch03_FINAL_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_Chapter02_segments.json (deflated 68%)\n",
            "  adding: ipcc_data/segments/AR6_WG2_IPCC_AR6_WGII_SummaryForPolicymakers_segments.json (deflated 73%)\n",
            "  adding: ipcc_data/segments/SREX_SREX-Chap6_FINAL-1_segments.json (deflated 70%)\n",
            "  adding: ipcc_data/segments/SROCC_04_SROCC_Ch02_FINAL_segments.json (deflated 67%)\n",
            "  adding: ipcc_data/segments/SR15_SR15_Chapter_1_LR_segments.json (deflated 70%)\n",
            "  adding: ipcc_data/segments/SRCCL_Chapter-3_FINAL-1_segments.json (deflated 66%)\n"
          ]
        }
      ]
    }
  ]
}